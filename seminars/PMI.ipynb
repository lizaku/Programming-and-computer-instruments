{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Коллокации и Pointwise Mutual Information (PMI)\n",
    "\n",
    "**Коллокация** - сочетание из двух или более слов, которое:\n",
    "\n",
    "1. обладает некомпозициональной семантикой.\n",
    "2. состоит из двух слов, которые встречаются вместе значимо часто.\n",
    "\n",
    "При лингвистическом анализе текста коллокации нам очень нужны по понятным причинам:\n",
    "\n",
    "* выявить, о чем текст\n",
    "* найти различия между текстами на схожую тематику\n",
    "* находить упоминания каких-то событий и персон\n",
    "* и т.д.\n",
    "\n",
    "Значит, нам нужно уметь выделять их автоматически. Чтобы найти коллокации, состоящие из двух слов, нам нужно выделить такие биграммы, которые встречаются друг с другом значимо часто, по сравнению с их индивидуальными частотами.\n",
    "\n",
    "Для выделения коллокаций существуют разные метрики. Мы познакомимся с одной из них, которая называется **[Pointwise Mutual Information (PMI)](https://en.wikipedia.org/wiki/Pointwise_mutual_information)**. Формула рассчета PMI - \n",
    "\n",
    "$$ pmi = log \\frac{{p(x,y)}}{p(x) \\cdot p(y)} $$\n",
    "\n",
    "* x и y - слова, входящие в биграмму;\n",
    "* p(x,y) - вероятность появления биграммы x + y;\n",
    "* p(x) и p(y) -- вероятность появления каждого из элементов биграммы в отдельности.\n",
    "\n",
    "Значит, чтобы посчитать PMI, нам нужно:\n",
    "\n",
    "* взять текст\n",
    "* сделать частотный список всех слов в тексте\n",
    "* найти вероятность появления каждого слова в тексте, разделив его частотность на общее количество слов\n",
    "* сделать частотный список всех биграмм в тексте\n",
    "* найти вероятность появления каждой биграммы в тексте, разделив её частотность на общее количество биграмм (а сколько их?)\n",
    "* найти pmi по формуле\n",
    "* биграммы с наибольшим pmi - коллокации в этом тексте.\n",
    "\n",
    "Давайте попробуем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from math import log\n",
    "\n",
    "punct = '[.,!«»?&@\"$\\[\\]\\(\\):;%#&\\'—-]'\n",
    "\n",
    "def preprocessing(text): # функция предобработки текста\n",
    "    text_wo_punct = re.sub(punct, '', text.lower()) # удаляем пунктуацию, приводим в нижний регистр\n",
    "    words = text_wo_punct.strip().split() # делим по пробелам\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../news.txt', 'r', encoding='utf-8') as f:\n",
    "    words = preprocessing(f.read())\n",
    "\n",
    "word_freq = {} # создаем частотный словарь для слов\n",
    "for word in words:\n",
    "    if word in word_freq:\n",
    "        word_freq[word] += 1\n",
    "    else:\n",
    "        word_freq[word] = 1\n",
    "\n",
    "bigrams = [] # в цикле собираем биграммы из двух следующих друг за другом слов\n",
    "for ind in range(1, len(words) - 1):\n",
    "    bigrams.append(' '.join([words[ind - 1], words[ind]]))\n",
    "    \n",
    "bigram_freq = {} # создаем частотный словарь для биграмм\n",
    "for b in bigrams:\n",
    "    if b in bigram_freq:\n",
    "        bigram_freq[b] += 1\n",
    "    else:\n",
    "        bigram_freq[b] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_pmi(x, y): # Вычисляем pmi\n",
    "    p_xy = bigram_freq[' '.join([x, y])]/len(bigrams) # считаем вероятность появления в тексте биграммы\n",
    "    p_x, p_y = word_freq[x]/len(words), word_freq[y]/len(words) # считаем вероятность появления в тексте слов по отдельности\n",
    "    pmi = log(p_xy/(p_x * p_y)) # по форму вычисляем pmi\n",
    "    return pmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "курсообразование чревато 12.07619172480532\n",
      "межведомственного электронного 12.07619172480532\n",
      "депозитарных расписок 12.07619172480532\n",
      "вызвавшие возражение 12.07619172480532\n",
      "плавающего операционного 12.07619172480532\n",
      "бинарных опционов 12.07619172480532\n",
      "макаронами консервами 12.07619172480532\n",
      "утратили обязательность 12.07619172480532\n",
      "привлекла двухлетний 12.07619172480532\n",
      "укрнафты днепроазотом 12.07619172480532\n",
      "контейнерными поездами 12.07619172480532\n",
      "сдвиг периодически 12.07619172480532\n",
      "дискретного аукциона 12.07619172480532\n",
      "относительной открытости 12.07619172480532\n",
      "оградиться стеной 12.07619172480532\n",
      "встречающие прорвали 12.07619172480532\n",
      "выстраивать оборонную 12.07619172480532\n",
      "излишки вагонного 12.07619172480532\n",
      "гарегин тосунян 12.07619172480532\n",
      "вячеславу жарову 12.07619172480532\n",
      "валютное рефинансирование 12.07619172480532\n",
      "мусоровозы прицепили 12.07619172480532\n",
      "распространился поверх 12.07619172480532\n",
      "option premium 12.07619172480532\n",
      "николас папаниколау 12.07619172480532\n",
      "продиктовано отложенным 12.07619172480532\n",
      "baev upgrading 12.07619172480532\n",
      "семьей евтушенковых 12.07619172480532\n",
      "названными имущественными 12.07619172480532\n",
      "орион 551 12.07619172480532\n",
      "ответным огнем 12.07619172480532\n",
      "контрольными пакетами 12.07619172480532\n",
      "продвижении националистически 12.07619172480532\n",
      "непримиримо боролась 12.07619172480532\n",
      "агитацией понимается 12.07619172480532\n",
      "кудимов 2033 12.07619172480532\n",
      "курсовым разницам 12.07619172480532\n",
      "прорывам 1960х 12.07619172480532\n",
      "ил96300 ту204/214 12.07619172480532\n",
      "маленькое замечание 12.07619172480532\n",
      "посетивших олимпийские 12.07619172480532\n",
      "джемилева национальноосвободительная 12.07619172480532\n",
      "подключает путинские 12.07619172480532\n",
      "найдена запрещенная 12.07619172480532\n",
      "рашид саутиев 12.07619172480532\n",
      "слабо легализованы 12.07619172480532\n",
      "владислава селезнева 12.07619172480532\n",
      "инвестиционному сотрудничеству 12.07619172480532\n",
      "складскими помещениями 12.07619172480532\n",
      "подарят полуострову 12.07619172480532\n",
      "жевачка белковые 12.07619172480532\n",
      "заняли пассивную 12.07619172480532\n",
      "аммиак холодильники 12.07619172480532\n",
      "участковый милиционер 12.07619172480532\n",
      "олландом премьерами 12.07619172480532\n",
      "никаким ассоциациям 12.07619172480532\n",
      "питер герви 12.07619172480532\n",
      "чьихто головах 12.07619172480532\n",
      "укрепленной стены 12.07619172480532\n",
      "биться посудимся 12.07619172480532\n",
      "физическая идентификация 12.07619172480532\n",
      "подрывает будущую 12.07619172480532\n",
      "озвученную ведевым 12.07619172480532\n",
      "интернета турне 12.07619172480532\n",
      "школу литературную 12.07619172480532\n",
      "репрессивный уклон 12.07619172480532\n",
      "дальнейший распад 12.07619172480532\n",
      "товарищей уязвимость 12.07619172480532\n",
      "кувшинников вологодская 12.07619172480532\n",
      "аналогичен запрету 12.07619172480532\n",
      "планово завершит 12.07619172480532\n",
      "владеющий телеканалом 12.07619172480532\n",
      "телеканалом ю 12.07619172480532\n",
      "итоговые протоколы 12.07619172480532\n",
      "сочинской олимпиаде 12.07619172480532\n",
      "западноуренгойскому североюбилейному 12.07619172480532\n",
      "детский сад 12.07619172480532\n",
      "ущемляет ничьих 12.07619172480532\n",
      "котировке марже 12.07619172480532\n",
      "деятельного раскаяния 12.07619172480532\n",
      "beyond antiwesternism 12.07619172480532\n",
      "демпартия правое 12.07619172480532\n",
      "владению пользованию 12.07619172480532\n",
      "неослабевающее геополитическое 12.07619172480532\n",
      "ударам высокоточного 12.07619172480532\n",
      "пропагандистского напора 12.07619172480532\n",
      "сибирьтехник новосибирск 12.07619172480532\n",
      "реальными оппонентами 12.07619172480532\n",
      "подготовил аналитическую 12.07619172480532\n",
      "вредные вещества 12.07619172480532\n",
      "социальному служению 12.07619172480532\n",
      "песок щебень 12.07619172480532\n",
      "дремучей советскости 12.07619172480532\n",
      "подкрепить преобразованием 12.07619172480532\n",
      "беспошлинной интернетторговли 12.07619172480532\n",
      "кафедрой политологии 12.07619172480532\n",
      "kapur surya 12.07619172480532\n",
      "ключи техпаспорт 12.07619172480532\n",
      "умеренной нисходящей 12.07619172480532\n",
      "древнему значению 12.07619172480532\n",
      "вуалью исключительной 12.07619172480532\n"
     ]
    }
   ],
   "source": [
    "pmi = {}\n",
    "for bigr in bigrams: # для всех биграмм вычисляем pmi\n",
    "    x, y = bigr.split()\n",
    "    pmi[bigr] = count_pmi(x, y)\n",
    "\n",
    "i = 0\n",
    "for bigram in sorted(pmi, key = lambda m: -pmi[m]): # сортируем по убыванию коэффициента, распечатываем 100 биграмм \n",
    "    if i > 100:                                     # с самым большим коэффициентом\n",
    "        break\n",
    "    print(bigram, pmi[bigram])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Какие слова имеют большой коэффициент pmi, а какие маленький?\n",
    "\n",
    "С помощью pmi можно также искать биграммы, специфичные для какой-то категории текстов. Для этого нам нужно всего лишь посчитать коэффициент PMI для слова/биграммы и категории.\n",
    "\n",
    "Например, у нас есть тексты 3 категорий. Посчитаем для слов в этих текстах коэффициент PMI, при этом в формуле X будет словом, а Y - категорией. (X, Y) - сколько раз слово X встретилось в текстах категории Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os # собираем тексты, раскладываем их по категориям\n",
    "anek = ''\n",
    "teh = ''\n",
    "izvest = ''\n",
    "for root, dirs, files in os.walk('texts'):\n",
    "    for f in files:\n",
    "        if 'anekdots' in root:\n",
    "            num_anek = len(files)\n",
    "            anek += open(os.path.join(root, f)).read()\n",
    "        elif 'izvest' in root:\n",
    "            num_izvest = len(files)\n",
    "            izvest += open(os.path.join(root, f)).read()\n",
    "        elif 'teh_mol' in root:\n",
    "            num_teh = len(files)\n",
    "            teh += open(os.path.join(root, f)).read()\n",
    "            \n",
    "words_anek = preprocessing(anek) # пропроцессинг\n",
    "words_teh = preprocessing(teh)\n",
    "words_izvest = preprocessing(izvest)\n",
    "\n",
    "words = words_anek + words_teh + words_izvest # в массиве words - весь наш корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def freq_dict(arr): # функция создания частотного словаря\n",
    "    dic = {}\n",
    "    for element in arr:\n",
    "        if element in dic:\n",
    "            dic[element] += 1\n",
    "        else:\n",
    "            dic[element] = 1\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_freq = freq_dict(words) # считаем частотные словари для каждой категории в отдельности и для всего корпуса\n",
    "anek_freq = freq_dict(words_anek)\n",
    "izvest_freq = freq_dict(words_izvest)\n",
    "teh_freq = freq_dict(words_teh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pmi_for_cats(x, y): # вычисляем pmi для слова и категории\n",
    "    if y == 'anek': # определяем, что за категория нам требуется, задаем её переменные (массив слов, число текстов)\n",
    "        dic = anek_freq\n",
    "        arr = words_anek\n",
    "        num = num_anek\n",
    "    elif y == 'teh':\n",
    "        dic = teh_freq\n",
    "        arr = words_teh\n",
    "        num = num_teh\n",
    "    elif y == 'izvest':\n",
    "        dic = izvest_freq\n",
    "        arr = words_izvest\n",
    "        num = num_izvest\n",
    "    p_xy = dic[x]/len(arr)\n",
    "    p_x, p_y = corpus_freq[x]/len(words), num/(num_izvest + num_teh + num_anek)\n",
    "    pmi = log(p_xy/(p_x * p_y))\n",
    "    return pmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "каптерке anek\n",
      "судостроители teh\n",
      "молодчина anek\n",
      "позволили izvest\n",
      "сфокусировать anek\n",
      "120 anek\n",
      "сник teh\n",
      "молодежь anek\n",
      "внутреннюю teh\n",
      "жидкость teh\n",
      "нарисуй anek\n",
      "считанные teh\n",
      "помыл anek\n",
      "мышеловку anek\n",
      "болель anek\n",
      "уходящих izvest\n",
      "констанции anek\n",
      "швеция teh\n",
      "разрядить anek\n",
      "расплатиться anek\n",
      "убедить izvest\n",
      "частоколом anek\n",
      "курнем anek\n",
      "полупромышленную teh\n",
      "однокривошипных teh\n",
      "сохранился teh\n",
      "тащит anek\n",
      "появившийся izvest\n",
      "проверял anek\n",
      "дивидендов anek\n",
      "классическими izvest\n",
      "научнотехническая teh\n",
      "зажаренную anek\n",
      "настеньку anek\n",
      "зашвырнул izvest\n",
      "малышку anek\n",
      "гулянки anek\n",
      "домогается anek\n",
      "котеночка anek\n",
      "ключито anek\n",
      "договорятся anek\n",
      "обрушившимся teh\n",
      "ванная anek\n",
      "укладывались teh\n",
      "восстановлению izvest\n",
      "лунном teh\n",
      "выстроив anek\n",
      "чувствует anek\n",
      "назовете teh\n",
      "бутылках anek\n",
      "может izvest\n",
      "бравый teh\n",
      "многообразии teh\n",
      "аккумуляторыто anek\n",
      "рейки teh\n",
      "государственников izvest\n",
      "запахло anek\n",
      "пальцем anek\n",
      "мао anek\n",
      "батенева izvest\n",
      "глобализации izvest\n",
      "опору teh\n",
      "microsoft izvest\n",
      "приводили teh\n",
      "древних teh\n",
      "штанишках anek\n",
      "открывай anek\n",
      "проектной izvest\n",
      "завязать anek\n",
      "причудливые teh\n",
      "появляющимся izvest\n",
      "шотландцы anek\n",
      "любит anek\n",
      "пользуются izvest\n",
      "аптечка anek\n",
      "поаккуратнее anek\n",
      "посадил anek\n",
      "оставим teh\n",
      "защищенному izvest\n",
      "армейская anek\n",
      "наболевшем izvest\n",
      "пораженным teh\n",
      "энергетическом teh\n",
      "спасательного anek\n",
      "горящим anek\n",
      "обратишь anek\n",
      "боязнь teh\n",
      "вопиющее teh\n",
      "информативны izvest\n",
      "катастрофам teh\n",
      "труднодоступные teh\n",
      "взаимное teh\n",
      "программный izvest\n",
      "письменное anek\n",
      "вставай anek\n",
      "техника teh\n",
      "превышают izvest\n",
      "разбрасывает teh\n",
      "желтые teh\n",
      "доледниковые teh\n",
      "хранимой izvest\n"
     ]
    }
   ],
   "source": [
    "cat_pmi = {}\n",
    "i = 0\n",
    "for word in corpus_freq:\n",
    "    if i > 100:\n",
    "        break\n",
    "    try:\n",
    "        pmi_anek = pmi_for_cats(word, 'anek')\n",
    "    except KeyError:\n",
    "        pmi_anek = 0\n",
    "    try:\n",
    "        pmi_teh = pmi_for_cats(word, 'teh')\n",
    "    except KeyError:\n",
    "        pmi_teh = 0\n",
    "    try:\n",
    "        pmi_izvest = pmi_for_cats(word, 'izvest')\n",
    "    except KeyError:\n",
    "        pmi_izvest = 0\n",
    "    max_pmi = max(pmi_anek, pmi_teh, pmi_izvest)\n",
    "    if max_pmi == 0:\n",
    "        continue\n",
    "    if max_pmi == pmi_anek:\n",
    "        cat = 'anek'\n",
    "    elif max_pmi == pmi_teh:\n",
    "        cat = 'teh'\n",
    "    elif max_pmi == pmi_izvest:\n",
    "        cat = 'izvest'\n",
    "    print(word, cat)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задания\n",
    "\n",
    "1. Отфильтровать слова, для которых мы вычисляем категории: убрать короткие и служебные, взять самые частотные.\n",
    "2. Изменить алгоритм вычисления категорий, в качестве P(x) взяв не частоту слова во всем корпусе, а частоту слова в текстах всех остальных категорий кроме той, для которой мы сейчас вычисляем PMI: то есть для pmi_anek - частоту слова в текстах teh_mol и izvest, для pmi_teh - частоту слова в текстах anek и izvest, и т.д.\n",
    "3. Соотнести биграммы с категориями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
